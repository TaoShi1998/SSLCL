# SSLCL: An Efficient Model-Agnostic Supervised Contrastive Learning Framework for Emotion Recognition in Conversations (Under Review by AAAI 2024)


## Introduction
Supervised Sample-Label Contrastive Learning with Soft-HGR Maximal Correlation (SSLCL) is an efficient and model-agnostic supervised contrastive learning framework for the problem of Emotion Recognition in Conversations (ERC), which eliminates the need for a large batch size and can be seamlessly integrated with existing ERC models without introducing any model-specific assumptions. 


## Model Architecture
The overall framework of SSLCL is illustrated as follows, which is made up of three key components: sample feature extraction, label learning, and sample-label contrastive learning. 
![Figure 1: Illustration of the overall framework of SSLCL.](https://github.com/TaoShi1998/SSLCL/assets/37060800/ca59e2f3-46e3-4d4c-85cd-6a79f34152f7)



